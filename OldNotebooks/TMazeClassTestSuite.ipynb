{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpDd4TVmQXhU",
        "outputId": "16332840-0415-48e5-8e7f-4392b27b3e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mlm-scoring'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 163 (delta 0), reused 3 (delta 0), pack-reused 156\u001b[K\n",
            "Receiving objects: 100% (163/163), 23.50 MiB | 12.05 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/mlm-scoring\n",
            "Collecting gluonnlp~=0.8.3\n",
            "  Downloading gluonnlp-0.8.3.tar.gz (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from mlm==0.1) (2022.6.2)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 12.5 MB/s \n",
            "\u001b[?25hCollecting mosestokenizer\n",
            "  Downloading mosestokenizer-1.2.1.tar.gz (37 kB)\n",
            "Collecting transformers~=3.3.1\n",
            "  Downloading transformers-3.3.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 71.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gluonnlp~=0.8.3->mlm==0.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers~=3.3.1->mlm==0.1) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers~=3.3.1->mlm==0.1) (3.7.1)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers~=3.3.1->mlm==0.1) (21.3)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 65.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers~=3.3.1->mlm==0.1) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from mosestokenizer->mlm==0.1) (0.6.2)\n",
            "Collecting openfile\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting uctools\n",
            "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
            "Collecting toolwrapper\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers~=3.3.1->mlm==0.1) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=3.3.1->mlm==0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=3.3.1->mlm==0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=3.3.1->mlm==0.1) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=3.3.1->mlm==0.1) (2.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->mlm==0.1) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=3.3.1->mlm==0.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=3.3.1->mlm==0.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers~=3.3.1->mlm==0.1) (1.1.0)\n",
            "Building wheels for collected packages: gluonnlp, mosestokenizer, sacremoses, toolwrapper, uctools\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.8.3-py3-none-any.whl size=293554 sha256=b8e3b9ebf58d37417eca2650aa794067c96eebb88854cc02467f595d51a4b78e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/11/a7/dbd80409d49af1066d14419f604dd823ab24cb4ebecde8db6e\n",
            "  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mosestokenizer: filename=mosestokenizer-1.2.1-py3-none-any.whl size=49189 sha256=687ff59c6ee29c032e85c5af192f9002af5073da755b9b7d601e40059962969a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/35/f7/af1258779a0b890abc3c79481460c597cb1f3659d0603cfb9d\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=fa697975e0ac6c47892ce80376a785d0bff60a4d28cff83fbb14397230d4a3b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/awslabs/mlm-scoring.git\n",
        "!pip install -e mlm-scoring/\n",
        "!pip install torch mxnet-cu101mkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqtkrYjJfuI5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "6de97a8e-e2c3-4195-ec67-0e57f8fa7606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/mlm-scoring/src'\n",
            "/content\n",
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8eacc4458f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mWORK_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/gdrive/My Drive/TMaze\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLMScorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLMScorerPT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLMScorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_pretrained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlm'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "%cd /content/mlm-scoring/src\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "WORK_PATH = \"/content/gdrive/My Drive/TMaze\"\n",
        "from mlm.scorers import MLMScorer, MLMScorerPT, LMScorer \n",
        "from mlm.models import get_pretrained\n",
        "import mxnet as mx\n",
        "import pickle\n",
        "import string\n",
        "from scipy.stats import norm\n",
        "import spacy\n",
        "import numpy as np #shouldn't need to import these\n",
        "import pandas as pd\n",
        "import sys\n",
        "sys.path.append(WORK_PATH)\n",
        "import tmaze #but can't import from within this file for some reason???? need setuptools\n",
        "\n",
        "#debugging libraries \n",
        "import copy\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOt14gHBOcAG"
      },
      "outputs": [],
      "source": [
        "ctxs = [mx.gpu(0)]\n",
        "#Uncomment following line If CPU only\n",
        "#ctxs = [mx.cpu()]\n",
        "model, vocab, tokenizer = get_pretrained(ctxs, 'bert-base-multi-cased') \n",
        "#hopefully this model is good enough, even though not exclusively trained on German - what's the best German model???\n",
        "#!python -m spacy download de_core_news_sm\n",
        "#nlp = spacy.load('de_core_news_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KleJ0WL9Pz24",
        "outputId": "f8be86b1-b7c7-4733-9d42-de6e92b59df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Created scorer of class 'MLMScorer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-20.469610914587975]\n"
          ]
        }
      ],
      "source": [
        "scorer = MLMScorer(model, vocab, tokenizer, ctxs)\n",
        "print(scorer.score_sentences([\"Ich will es ausprobieren.\"]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UWu6HlIgGWBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQFRrwoVECQU"
      },
      "outputs": [],
      "source": [
        "#Making sure that these are lower - yes, second is worse than the first, not sure whether this makes sense\n",
        "print(scorer.score_sentences([\"Ich will ich ausprobieren.\"])) \n",
        "print(scorer.score_sentences([\"Ich will Katze ausprobieren.\"])) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_dict = {\"freq_dict\":f\"{WORK_PATH}/FreqToWords.pkl\", \"word_info\": f\"{WORK_PATH}/WordInfo.pkl\", \"nonwords_set\": f\"{WORK_PATH}/NonwordsSet.pkl\",\n",
        "               \"dists_dict\": f\"{WORK_PATH}/PotentialDistractors.pkl\"}"
      ],
      "metadata": {
        "id": "yN-4rzL3IPQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "empty_dict = {}\n",
        "with open(pickle_dict['dists_dict'], \"wb\") as f:\n",
        "  pickle.dump(empty_dict,f)"
      ],
      "metadata": {
        "id": "qTeKnCnKkJ6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = tmaze.tmaze(scorer,'de_core_news_sm',WORK_PATH,pickle_dict)"
      ],
      "metadata": {
        "id": "E40IVnpMGtiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwmQofC3MOcM"
      },
      "outputs": [],
      "source": [
        "with open(f'{WORK_PATH}/FormattedTestItems.txt') as f: #combined fillers and test sentences \n",
        "    sents = f.readlines() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzrm7mLBDMZ3"
      },
      "outputs": [],
      "source": [
        "#Create separate lists for the experimental and filler sentences \n",
        "exp_sent_lists = []\n",
        "filler_sent_lists = []\n",
        "for sent in sents:\n",
        "  sent_info = sent.split(\";\")\n",
        "  if sent_info[0] == \"filler\":\n",
        "    filler_sent_lists+=[sent_info[2].split()]\n",
        "  else:\n",
        "    exp_sent_lists+=[sent_info[2].split()]\n",
        "exp_sent_lists_copy = copy.deepcopy(exp_sent_lists)\n",
        "filler_sent_lists_copy = copy.deepcopy(filler_sent_lists)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPN4XDzFD0xF",
        "outputId": "5ab3f883-5c8b-4a5d-da9c-91ed485dfda0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n",
            "90\n"
          ]
        }
      ],
      "source": [
        "print(len(filler_sent_lists))\n",
        "print(len(exp_sent_lists))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{WORK_PATH}/FreqToWords.pkl','rb') as f:\n",
        "    freq_dict_copy = pickle.load(f)"
      ],
      "metadata": {
        "id": "p9nzru7XTLd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{WORK_PATH}/WordInfo.pkl','rb') as f: \n",
        "    word_info_copy = pickle.load(f)"
      ],
      "metadata": {
        "id": "6lsMWKXrTO8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{WORK_PATH}/NonwordsSet.pkl\", \"rb\") as f:\n",
        "    nonwords_set_copy = pickle.load(f)"
      ],
      "metadata": {
        "id": "lX2xN5HITTs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sent = sents[0].split(\";\")[2].split()\n",
        "test_sent_copy = test_sent[:]"
      ],
      "metadata": {
        "id": "HOah9CPl-Xxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glNQwiiOE2dF",
        "outputId": "fc7e78dd-64d8-4f05-f91a-119daabacaec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xxx Mutter von Paula und die Schwester von Sophie grüßten den Direktor, den Maria und Franziska ignoriert hatten.\n",
            "Die Mutter von Paula und die Schwester von Sophie grüßten den Direktor, den Maria und Franziska ignoriert xxx.\n",
            "Die Mutter von Paula und die Schwester von Sophie grüßten den xxx, den Maria und Franziska ignoriert hatten.\n",
            "Die Mutter von Paula und die Schwester von Sophie grüßten den Direktor, den Maria und Franziska xxx hatten.\n",
            "Die Mutter von Paula und die Schwester von Sophie grüßten den Direktor, den Maria und xxx ignoriert hatten.\n",
            "Die Mutter von Paula xxx die Schwester von Sophie grüßten den Direktor, den Maria und Franziska ignoriert hatten.\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "#case 1 test\n",
        "distractor = \"xxx\"\n",
        "print(test.create_sent(0,distractor,test_sent)) \n",
        "#case 2 test\n",
        "print(test.create_sent(len(test_sent)-1,distractor,test_sent))\n",
        "#middle of sentence punct case\n",
        "print(test.create_sent(11,distractor,test_sent))\n",
        "#general case\n",
        "inds = np.random.randint(1,len(test_sent)-1,3)\n",
        "for i in inds:\n",
        "  print(test.create_sent(i,distractor,test_sent))\n",
        "print(test_sent == test_sent_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEztY5xtFDMt",
        "outputId": "91ac8ab9-d458-44e9-acd4-4db4cb108562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die xxx\n",
            "Die Mutter von Paula und die Schwester von Sophie grüßten den Direktor, den Maria und Franziska ignoriert xxx.\n",
            "Die Mutter von Paula und die Schwester von Sophie grüßten den xxx,\n",
            "Die Mutter von Paula xxx\n",
            "Die Mutter von Paula und die Schwester von Sophie grüßten xxx\n",
            "Die Mutter von Paula und die Schwester von Sophie grüßten den xxx,\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "#testing just_preceding parameter\n",
        "print(test.create_sent(1,distractor,test_sent,True)) \n",
        "#case 2 test\n",
        "print(test.create_sent(len(test_sent)-1,distractor,test_sent,True))\n",
        "#middle of sentence punct case\n",
        "print(test.create_sent(11,distractor,test_sent,True))\n",
        "#general case\n",
        "inds = np.random.randint(1,len(test_sent)-1,3)\n",
        "for i in inds:\n",
        "  print(test.create_sent(i,distractor,test_sent,True))\n",
        "print(test_sent == test_sent_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_LDtbZ5GLtE",
        "outputId": "3a8b312b-d4e3-4e95-a0e5-986904e2fd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, ''), (0, ''), (0, '')]\n",
            "[(0, ''), (0, ''), (0, ''), (0, ''), (0, '')]\n",
            "[(0, ''), (0, ''), (0, ''), (0, ''), (0, ''), (0, ''), (0, ''), (0, ''), (0, ''), (0, '')]\n"
          ]
        }
      ],
      "source": [
        "for i in [3,5,10]:\n",
        "  print(test.init_best_list(i))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dists = [\"hallo\",\"ich\",\"mag\",\"pizza\"]\n",
        "print(test.any_tagged(dists))\n",
        "dists = [\"hallo\", (\"ich\",\"PRON\"), (\"mag\",\"VVFIN\"),\"pizza\"]\n",
        "print(test.any_tagged(dists))\n",
        "dists = [(\"ich\",\"PRON\"), (\"mag\",\"VVFIN\")]\n",
        "print(test.any_tagged(dists)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kNXJX8cHymN",
        "outputId": "f53ea626-f326-464d-bb2e-a7d4a4fa0d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(False, False)\n",
            "(False, True)\n",
            "(True, True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQHiNN85HnbL",
        "outputId": "21b16cab-6bd2-4aa0-a8ad-4ca2412e72df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([(-73.29378584303777, 'pizza'), (-75.34832774451934, 'hallo'), (-77.28522683499614, 'mag')], {'mag', 'hallo', 'ich', 'pizza'})\n",
            "([(-64.17616746784188, 'ich'), (-69.6569750359049, 'mag'), (-72.00143465620931, 'hallo')], {'mag', 'hallo', 'ich', 'pizza'})\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluonnlp/data/sampler.py:354: UserWarning: Some buckets are empty and will be removed. Unused bucket keys=[29]\n",
            "  str(unused_bucket_keys))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([(-69.6569750359049, 'mag'), (-72.00143465620931, 'hallo'), (-72.09987840690883, 'das')], {'freut', 'gut', 'mich', 'das'})\n",
            "([(-68.51866429304937, 'gut'), (-69.6569750359049, 'mag'), (-72.00143465620931, 'hallo')], {'freut', 'gut', 'mich', 'das'})\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluonnlp/data/sampler.py:354: UserWarning: Some buckets are empty and will be removed. Unused bucket keys=[10]\n",
            "  str(unused_bucket_keys))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([(-68.51866429304937, 'gut'), (-69.6569750359049, 'mag'), (-72.00143465620931, 'hallo')], {'du', 'magst', 'pizza', 'auch'})\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "#PLLs change with each restart even with same context\n",
        "#TODO: do more thorough testing/printing\n",
        "#Matches what's going on in other notebook pretty well though\n",
        "dists = [\"hallo\",\"ich\",\"mag\",\"pizza\"]\n",
        "dists_copy = dists[:]\n",
        "best_list = test.init_best_list(3)\n",
        "print(test.eval_best(2,dists,test_sent,best_list))\n",
        "test_ind = 6 #arbitrary - feel free to change\n",
        "best_list = test.init_best_list(3)\n",
        "best_so_far,evaluated = test.eval_best(test_ind,dists,test_sent,best_list) \n",
        "print((best_so_far,evaluated))\n",
        "print(dists == dists_copy)\n",
        "new_dists = [\"gut\",\"das\",\"freut\",\"mich\"]\n",
        "new_dists_copy = new_dists[:]\n",
        "print(test.eval_best(test_ind,new_dists,test_sent,best_so_far))\n",
        "print(test.eval_best(test_ind,new_dists,test_sent,best_so_far,just_preceding=True)) #should give different PLLs\n",
        "print(new_dists == new_dists_copy)\n",
        "new_dists = [(\"du\",\"PRON\"),(\"magst\",\"VVFIN\"),(\"pizza\",\"NE\"), (\"auch\",\"ADV\")]\n",
        "new_dists_copy = new_dists[:]\n",
        "print(test.eval_best(test_ind,new_dists,test_sent,best_so_far,True))\n",
        "print(new_dists == new_dists_copy)\n",
        "#NOTE: tagged and untagged can be mixed - not that this is an anticipated use case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be1_X9oCt8tF",
        "outputId": "c448b8eb-7fdb-4e05-bde9-c86329c7ef03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8, 9]\n",
            "[6, 7]\n",
            "[2, 6]\n",
            "[2, 5]\n",
            "[10, 13]\n",
            "[5, 7]\n",
            "[6, 7]\n",
            "[5, 8]\n",
            "[3, 8]\n",
            "[2, 9]\n"
          ]
        }
      ],
      "source": [
        "#test normal distribution way of getting good length range for distractors\n",
        "#all with 20% of normal curve included in the range \n",
        "print(test.get_len_range(9))\n",
        "print(test.get_len_range(7))\n",
        "print(test.get_len_range(5))\n",
        "print(test.get_len_range(3))\n",
        "print(test.get_len_range(12))\n",
        "#now with different percentages\n",
        "print(test.get_len_range(7,0.3))\n",
        "print(test.get_len_range(7,0.1))\n",
        "print(test.get_len_range(7,0.45))\n",
        "print(test.get_len_range(7,0.6))\n",
        "print(test.get_len_range(7,0.85))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q94SZyQH7-R",
        "outputId": "b9e85d06-8b05-4952-f39a-cea05f256c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Mutter gut:ADJD\n",
            "Die Mutter von Paula und die das:ART\n",
            "Die Mutter von freut:NE\n",
            "Die Mutter von Paula und die mich:PPER\n",
            "True\n",
            "Die:ART\n",
            "Die neuen:ADJA\n",
            "Die neuen Biersorten:NN\n",
            "Die neuen Biersorten der:ART\n",
            "Die neuen Biersorten der Brauerei:NN\n",
            "Die neuen Biersorten der Brauerei enthalten:ADJD\n",
            "Die neuen Biersorten der Brauerei enthalten 6%:CARD\n",
            "Die neuen Biersorten der Brauerei enthalten 6% Alkohol,:NN\n",
            "Die neuen Biersorten der Brauerei enthalten 6% Alkohol, was:PWS\n",
            "Die neuen Biersorten der Brauerei enthalten 6% Alkohol, was für:APPR\n",
            "Die neuen Biersorten der Brauerei enthalten 6% Alkohol, was für mich:PPER\n",
            "Die neuen Biersorten der Brauerei enthalten 6% Alkohol, was für mich etwas:PIS\n",
            "Die neuen Biersorten der Brauerei enthalten 6% Alkohol, was für mich etwas zu:PTKZU\n",
            "Die neuen Biersorten der Brauerei enthalten 6% Alkohol, was für mich etwas zu viel:PIS\n",
            "Die neuen Biersorten der Brauerei enthalten 6% Alkohol, was für mich etwas zu viel ist.:VAFIN\n",
            "Die neuen Biersorten der Brauerei enthalten nizza%:$,\n",
            "Die neuen Biersorten der Brauerei enthalten wie%:NN\n"
          ]
        }
      ],
      "source": [
        "dists = [\"gut\",\"das\",\"freut\",\"mich\"]\n",
        "dists_copy = dists[:]\n",
        "inds = np.random.randint(1,len(test_sent),4)\n",
        "for i in range(len(dists)):\n",
        "  if i > 1:\n",
        "    print(f'{test.create_sent(inds[i],dists[i],test_sent,True)}:{test.get_tag(dists[i],inds[i],test_sent,True)}')\n",
        "  else:\n",
        "    print(f'{test.create_sent(inds[i],dists[i],test_sent,True)}:{test.get_tag(dists[i],inds[i],test_sent,False)}')\n",
        "print(dists == dists_copy)\n",
        "filler_sent = filler_sent_lists[57] \n",
        "for i in range(len(filler_sent)):\n",
        "  if filler_sent[i][-1] in string.punctuation:\n",
        "    dist = filler_sent[i][:-1] #distractor won't come with punctuation\n",
        "  else:\n",
        "    dist = filler_sent[i]\n",
        "  print(f'{test.create_sent(i,dist,filler_sent,True)}:{test.get_tag(dist,i,filler_sent,True)}')\n",
        "dist = \"nizza\" \n",
        "print(f'{test.create_sent(6,dist,filler_sent,True)}:{test.get_tag(dist,6,filler_sent,True)}')\n",
        "dist = \"wie\"\n",
        "print(f'{test.create_sent(6,dist,filler_sent,True)}:{test.get_tag(dist,6,filler_sent,True)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IYq1s3WLpAW",
        "outputId": "67e4afd7-ff1d-4c64-9ac6-2f21a43d03ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Mutter von Paula und ___ Schwester von Sophie grüßten den Direktor, den Maria und Franziska ignoriert hatten.\n",
            "[('ich', 'PPER'), ('habe', 'VAFIN'), ('viel', 'PIAT'), ('hunger', 'ADJA')]\n",
            "True\n",
            "Die Mutter von Paula und die Schwester ___ Sophie grüßten den Direktor, den Maria und Franziska ignoriert hatten.\n",
            "['wie', 'fuhlst', 'Du', 'dich']\n",
            "True\n",
            "Die Mutter von Paula und die Schwester von Sophie grüßten den Direktor, den Maria und ___ ignoriert hatten.\n",
            "Franziska,NE\n",
            "Die Mutter von Paula und ___            \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIAT'), ('zusammen', 'ADV'), ('gehen', 'VVINF')]\n",
            "True\n",
            "Die ___                \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'ADV'), ('gehen', 'VVFIN')]\n",
            "Die Pakete, ___               \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'ADV'), ('gehen', 'VVFIN')]\n",
            "Die Pakete, die ___              \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'ADV'), ('gehen', 'VVFIN')]\n",
            "Die Pakete, die zur ___             \n",
            "[('wir', 'PPER'), ('können', 'VMINF'), ('alle', 'PIS'), ('zusammen', 'ADV'), ('gehen', 'VVINF')]\n",
            "Die Pakete, die zur Post ___            \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'PTKVZ'), ('gehen', 'VVFIN')]\n",
            "Die Pakete, die zur Post müssen, ___           \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'PTKVZ'), ('gehen', 'VVINF')]\n",
            "Die Pakete, die zur Post müssen, wiegen ___          \n",
            "[('wir', 'PPER'), ('können', 'VMINF'), ('alle', 'PIS'), ('zusammen', 'PTKVZ'), ('gehen', 'VVINF')]\n",
            "Die Pakete, die zur Post müssen, wiegen 5 ___         \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'PTKVZ'), ('gehen', 'VVINF')]\n",
            "Die Pakete, die zur Post müssen, wiegen 5 Kilo ___        \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'PTKVZ'), ('gehen', 'VVINF')]\n",
            "Die Pakete, die zur Post müssen, wiegen 5 Kilo und ___       \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'ADV'), ('gehen', 'VVFIN')]\n",
            "Die Pakete, die zur Post müssen, wiegen 5 Kilo und sind ___      \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'ADV'), ('gehen', 'VVINF')]\n",
            "Die Pakete, die zur Post müssen, wiegen 5 Kilo und sind alle ___     \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'PTKVZ'), ('gehen', 'VVINF')]\n",
            "Die Pakete, die zur Post müssen, wiegen 5 Kilo und sind alle zusammen ___    \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'ADV'), ('gehen', 'VVINF')]\n",
            "Die Pakete, die zur Post müssen, wiegen 5 Kilo und sind alle zusammen wohl ___   \n",
            "[('wir', 'PPER'), ('können', 'VMFIN'), ('alle', 'PIS'), ('zusammen', 'ADV'), ('gehen', 'VVINF')]\n",
            "Die Pakete, die zur Post müssen, wiegen 5 Kilo und sind alle zusammen wohl zu ___  \n",
            "[('wir', 'PPER'), ('können', 'VMINF'), ('alle', 'PIS'), ('zusammen', 'PTKVZ'), ('gehen', 'VVINF')]\n",
            "Die Pakete, die zur Post müssen, wiegen 5 Kilo und sind alle zusammen wohl zu schwer ___ \n",
            "[('wir', 'PPER'), ('können', 'VMINF'), ('alle', 'PIS'), ('zusammen', 'PTKVZ'), ('gehen', 'VVINF')]\n",
            "Die Pakete, die zur Post müssen, wiegen 5 Kilo und sind alle zusammen wohl zu schwer für ___\n",
            "[('wir', 'PPER'), ('können', 'VMINF'), ('alle', 'PIS'), ('zusammen', 'PTKVZ'), ('gehen', 'VVINF')]\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "def display_context(test_sent,ind,just_preceding=False):\n",
        "  sent = \"\"\n",
        "  for i in range(len(test_sent)):\n",
        "    if i==ind:\n",
        "      sent+=\"___\"\n",
        "    elif i < ind or (i > ind and not just_preceding):\n",
        "      sent+=test_sent[i]\n",
        "    sent+=\" \"\n",
        "  print(sent[:-1])\n",
        "\n",
        "#just default paramaters\n",
        "dists = [\"ich\", \"habe\", \"viel\", \"hunger\"]\n",
        "dists_copy = dists[:]\n",
        "ind = np.random.randint(1,len(test_sent))\n",
        "display_context(test_sent,ind)\n",
        "print(test.pos_shennanigans(dists,ind,test_sent))\n",
        "print(dists == dists_copy)\n",
        "\n",
        "#flip tagged parameter\n",
        "dists = [\"wie\", \"fuhlst\", \"du\", \"dich\"]\n",
        "dists_copy = dists[:]\n",
        "ind = np.random.randint(1,len(test_sent))\n",
        "display_context(test_sent,ind)\n",
        "#should just return the distractors but properly capitalized\n",
        "print(test.pos_shennanigans(dists,ind,test_sent,tagged=False)) \n",
        "print(dists == dists_copy)\n",
        "\n",
        "#TODO: FIX THIS TEST\n",
        "#add compare_tag \n",
        "dists = [\"sie\", \"will\", \"frühstuck\", \"essen\"]\n",
        "dists_copy = dists[:]\n",
        "ind = np.random.randint(1,len(test_sent))\n",
        "sent = f\"{test_sent[:ind]} ___ {test_sent[ind+1:]}\"\n",
        "word_to_replace = test_sent[ind]\n",
        "tag = test.get_tag(word_to_replace, ind, test_sent, False)\n",
        "display_context(test_sent,ind)\n",
        "print(f'{word_to_replace},{tag}')\n",
        "#doesn't capitalize Frühstuck because tagging isn't a solved problem\n",
        "#print(test.pos_shennanigans(dists,ind,test_sent,{\"Frühstuck\"},compare_tag=tag)) \n",
        "#print(dists == dists_copy)\n",
        "\n",
        "#flip just_preceding parameter\n",
        "dists = [\"wir\", \"können\", \"alle\", \"zusammen\", \"gehen\"]\n",
        "dists_copy = dists[:]\n",
        "ind = np.random.randint(1,len(test_sent))\n",
        "display_context(test_sent,ind,True)\n",
        "print(test.pos_shennanigans(dists,ind,test_sent,just_preceding=True))\n",
        "print(dists == dists_copy)\n",
        "\n",
        "#failing on this in later test case\n",
        "sent_ind = 51\n",
        "sent = filler_sent_lists[sent_ind]\n",
        "for i in range(1, len(sent)):\n",
        "  display_context(sent,i,True)\n",
        "  print(test.pos_shennanigans(dists,i,sent, just_preceding=True))\n",
        "print(dists == dists_copy)\n",
        "print(test_sent == test_sent_copy)\n",
        "print(test.nonwords_set == nonwords_set_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cMbw75jM2dA",
        "outputId": "a7aabc2b-9a30-4186-c37a-2970a0fac65b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([8.799999999999999, 0.22], [7.7, 7.7])\n",
            "True\n",
            "True\n",
            "True\n",
            "[8.7, 0.2] [6.890000000000001, 7.31]\n",
            "True\n",
            "True\n",
            "True\n",
            "([8.7, 0.2], [6.890000000000001, 7.31])\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "init_params = [8.7,0.2]\n",
        "temp_freqs = [6.7,8.7]\n",
        "targets = (6,7.7)\n",
        "params_copy = init_params[:]\n",
        "temp_freqs_copy = temp_freqs[:]\n",
        "targets_copy = targets #tuples are imutable\n",
        "#case where we're about to go over\n",
        "print(test.adjust_params(init_params,temp_freqs,targets,True)) \n",
        "print(init_params == params_copy)\n",
        "print(temp_freqs == temp_freqs_copy)\n",
        "print(targets == targets_copy)\n",
        "\n",
        "#changes its parameters - intended\n",
        "temp_freqs = [6.9,7.3]\n",
        "targets = (6,7.1)\n",
        "temp_freqs_copy = temp_freqs[:]\n",
        "targets_copy = targets\n",
        "params, new_temp_freqs = test.adjust_params(init_params,temp_freqs,targets,True) #just increase temp_freqs\n",
        "print(params,new_temp_freqs)\n",
        "print(init_params == params_copy and params_copy == params)\n",
        "print(temp_freqs == temp_freqs_copy)\n",
        "print(targets == targets_copy)\n",
        "\n",
        "#the floating point errors are corrected right before checking the dictionary for the values\n",
        "print(test.adjust_params(params,new_temp_freqs,targets,False)) #nothing should happen because we need to keep working through that bin\n",
        "print(init_params == params_copy and params_copy == params)\n",
        "print(temp_freqs == temp_freqs_copy)\n",
        "print(targets == targets_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obXZoy1zS61T",
        "outputId": "1a199eb0-61bf-473e-e840-32737d8de7c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Bäckerin [Mutter]\n",
            "Unacceptable? 0\n",
            "Die Mutter von Paula und die Schwester von Sophie grüßten den Direktor, Bäckerin [den]\n",
            "Unacceptable? 1\n",
            "Die Mutter von Paula und die Schwester Bäckerin [von]\n",
            "Unacceptable? 0\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "dist = \"Bäckerin\"\n",
        "test.get_rating(dist,1,test_sent)\n",
        "test.get_rating(dist,12,test_sent)\n",
        "test.get_rating(dist,7,test_sent)\n",
        "print(test_sent == test_sent_copy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Some dummy test cases\n",
        "dummy_dist_dict = {} #could be an object itself\n",
        "new_dists = [\"yo\",\"sup\",\"does\",\"this\",\"work\"]\n",
        "word = \"word\"\n",
        "test.add_to_distractor_dict(word,new_dists,dummy_dist_dict)\n",
        "print(dummy_dist_dict)\n",
        "test.dists_dict = dummy_dist_dict\n",
        "print(test.check_for_potential_distractors(\"new\",100))\n",
        "print(test.check_for_potential_distractors(word,5))\n",
        "print(test.check_for_potential_distractors(word,100))\n",
        "more_dists = [\"time\",\"to\",\"add\",\"some\",\"more\"]\n",
        "test.add_to_distractor_dict(word,more_dists,dummy_dist_dict)\n",
        "print(test.check_for_potential_distractors(word,5,))\n",
        "print(test.dists_dict)\n",
        "#reset dists_dict to its original\n",
        "with open(pickle_dict[\"dists_dict\"], \"rb\") as f:\n",
        "  test.dists_dict = pickle.load(f) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkkUciDW1Ilt",
        "outputId": "e2f8ed86-1756-498f-dc05-6ad12c32adfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'word': {'work', 'does', 'this', 'yo', 'sup'}}\n",
            "([], 0)\n",
            "(['work', 'does', 'this', 'yo', 'sup'], 5)\n",
            "(['work', 'does', 'this', 'yo', 'sup'], 5)\n",
            "(['work', 'does', 'this', 'time', 'more', 'yo'], 5)\n",
            "{'word': {'work', 'does', 'this', 'time', 'more', 'yo', 'to', 'sup', 'some', 'add'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.pickle_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijA1p57pYmBv",
        "outputId": "1acbdaa4-945c-4a0e-c9ed-3daf12913e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dists_dict': '/content/gdrive/My Drive/TMaze/PotentialDistractors.pkl',\n",
              " 'freq_dict': '/content/gdrive/My Drive/TMaze/FreqToWords.pkl',\n",
              " 'nonwords_set': '/content/gdrive/My Drive/TMaze/NonwordsSet.pkl',\n",
              " 'word_info': '/content/gdrive/My Drive/TMaze/WordInfo.pkl'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzAHnE4Ge9g7"
      },
      "source": [
        "Parameters to test:\n",
        "* tagged ✅\n",
        "* use_tag ✅\n",
        "* filler ✅\n",
        "* just_preceding ✅\n",
        "* rate ✅\n",
        "* dist_df ✅\n",
        "* dist_csv ✅\n",
        "* save_csv\n",
        "  * boolean ✅\n",
        "  * string ✅\n",
        "* multi ✅\n",
        "* verbose ✅\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O50_pzPXHRD",
        "outputId": "8bfa060e-7e26-4702-9bf0-515fb3c2bdc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: und, Tag: KON\n",
            "7.42\n",
            "Time to evaluate >10 distractors: 0.21800518035888672\n",
            "Final parameter settings: 7.52 0.2\n",
            "Vanessa laden [und]\n",
            "Unacceptable? 1\n",
            "Vanessa Tage [und]\n",
            "Unacceptable? 0\n",
            "Vanessa wovon [und]\n",
            "Unacceptable? 1\n",
            "/content/gdrive/My Drive/TMaze/PotentialDistractors.pkl\n",
            "  Distractor Index    POS Sent Index Filler Replaced_Word Replaced_POS  \\\n",
            "0      laden     1  VVINF         80  False           und          KON   \n",
            "1       Tage     1     NN         80  False           und          KON   \n",
            "2      wovon     1   PWAV         80  False           und          KON   \n",
            "\n",
            "         PLL  PLL norm Number Evaluated Best N Ranking Rating  Evaluation Time  \n",
            "0 -30.130128 -6.026026               10      3       3      1         0.218005  \n",
            "1 -31.504324 -7.876081               10      3       2      0         0.218005  \n",
            "2 -35.829246 -7.165849               10      3       1      1         0.218005  \n",
            "All the following should be true if we're not mutating anything that we shouln't be.\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "76\n",
            "7.42\n",
            "Time to evaluate >10 distractors: 0.21201276779174805\n",
            "Final parameter settings: 7.52 0.2\n",
            "Sonja erben [und]\n",
            "Unacceptable? 1\n",
            "Sonja nein [und]\n",
            "Unacceptable? 1\n",
            "Sonja wovon [und]\n",
            "Unacceptable? 1\n",
            "/content/gdrive/My Drive/TMaze/PotentialDistractors.pkl\n",
            "  Distractor Index     POS Sent Index Filler Replaced_Word Replaced_POS  \\\n",
            "0      erben     1   VVIZU         74  False           und          KON   \n",
            "1       nein     1  PTKANT         74  False           und          KON   \n",
            "2      wovon     1    PWAV         74  False           und          KON   \n",
            "\n",
            "         PLL  PLL norm Number Evaluated Best N Ranking Rating  Evaluation Time  \n",
            "0 -31.269258 -6.253852               10      3       3      1         0.212013  \n",
            "1 -32.895782 -8.223945               10      3       2      1         0.212013  \n",
            "2 -40.174137 -8.034827               10      3       1      1         0.212013  \n",
            "All the following should be true if we're not mutating anything that we shouldn't be.\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "76\n"
          ]
        }
      ],
      "source": [
        "#Check that we won't save duplicates\n",
        "#Testing use_tag annd verbose\n",
        "sent_ind = 80\n",
        "test_sent = exp_sent_lists[sent_ind]\n",
        "test_sent_copy = test_sent[:]\n",
        "dist_ind = 1\n",
        "print(test.batch_eval(dist_ind,test_sent,sent_ind,10,3,use_tag=True,verbose=True)) \n",
        "#Only predetermine the tag in the case of use_tag\n",
        "print(\"All the following should be true if we're not mutating anything that we shouln't be.\")\n",
        "print(test_sent == test_sent_copy)\n",
        "print(test.nonwords_set == nonwords_set_copy)\n",
        "print(test.word_info == word_info_copy)\n",
        "print(test.freq_dict == freq_dict_copy)\n",
        "print(len(test.dists_dict)) #too big to print after having used it for many rounds\n",
        "\n",
        "sent_ind = 74\n",
        "test_sent = exp_sent_lists[sent_ind]\n",
        "test_sent_copy = test_sent[:]\n",
        "dist_ind = 1\n",
        "print(test.batch_eval(dist_ind,test_sent,sent_ind,10,3))\n",
        "print(\"All the following should be true if we're not mutating anything that we shouldn't be.\")\n",
        "print(test_sent == test_sent_copy)\n",
        "print(test.nonwords_set == nonwords_set_copy)\n",
        "print(test.word_info == word_info_copy)\n",
        "print(test.freq_dict == freq_dict_copy)\n",
        "print(len(test.dists_dict)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D08LkxdAG7zc",
        "outputId": "ccfe2c92-5428-4345-e9c6-7817e0fe7d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.42\n",
            "Time to evaluate >10 distractors: 0.20922303199768066\n",
            "Final parameter settings: 7.52 0.2\n",
            "Sonja nähe [und]\n",
            "Unacceptable? 1\n",
            "Sonja raum [und]\n",
            "Unacceptable? 1\n",
            "Sonja voran [und]\n",
            "Unacceptable? 1\n",
            "Some of these probably won't be new...\n",
            "7.42\n",
            "Time to evaluate >20 distractors: 0.21239924430847168\n",
            "Final parameter settings: 7.52 0.2\n",
            "Sonja gutem [und]\n",
            "Unacceptable? 1\n",
            "Sonja weile [und]\n",
            "Unacceptable? 1\n",
            "Sonja wüste [und]\n",
            "Unacceptable? 0\n",
            "7.42\n",
            "Time to evaluate >10 distractors: 0.21112370491027832\n",
            "Final parameter settings: 7.52 0.2\n",
            "  Distractor Index    POS Sent Index Filler Replaced_Word Replaced_POS  \\\n",
            "0       nähe     1  VVFIN         73  False           und          KON   \n",
            "1       raum     1  VVFIN         73  False           und          KON   \n",
            "2      voran     1  PTKVZ         73  False           und          KON   \n",
            "3      gutem     1  VVFIN         73  False           und          KON   \n",
            "4      weile     1  VVFIN         73  False           und          KON   \n",
            "5      wüste     1  VVFIN         73  False           und          KON   \n",
            "6       nähe     1  VVFIN         52  False           und          KON   \n",
            "7       hohe     1  VVFIN         52  False           und          KON   \n",
            "8       raum     1  VVFIN         52  False           und          KON   \n",
            "\n",
            "         PLL  PLL norm Number Evaluated Best N Ranking Rating  Evaluation Time  \n",
            "0 -29.300632 -7.325158               10      3       3      1         0.209223  \n",
            "1 -30.884974 -7.721244               10      3       2      1         0.209223  \n",
            "2 -30.950538 -6.190108               10      3       1      1         0.209223  \n",
            "3 -32.395498 -6.479100               20      3       3      1         0.212399  \n",
            "4 -34.299638 -6.859928               20      3       2      1         0.212399  \n",
            "5 -37.470257 -7.494051               20      3       1      0         0.212399  \n",
            "6 -28.673032 -7.168258               10      3       3   None         0.211124  \n",
            "7 -29.536135 -7.384034               10      3       2   None         0.211124  \n",
            "8 -31.982967 -7.995742               10      3       1   None         0.211124  \n",
            "7.48\n",
            "Time to evaluate >10 distractors: 0.20911097526550293\n",
            "Final parameter settings: 7.58 0.2\n",
            "Lea und nähe [die]\n",
            "Unacceptable? 1\n",
            "Lea und can [die]\n",
            "Unacceptable? 1\n",
            "Lea und bands [die]\n",
            "Unacceptable? 1\n",
            "   Distractor Index    POS Sent Index Filler Replaced_Word Replaced_POS  \\\n",
            "0        nähe     1  VVFIN         73  False           und          KON   \n",
            "1        raum     1  VVFIN         73  False           und          KON   \n",
            "2       voran     1  PTKVZ         73  False           und          KON   \n",
            "3       gutem     1  VVFIN         73  False           und          KON   \n",
            "4       weile     1  VVFIN         73  False           und          KON   \n",
            "5       wüste     1  VVFIN         73  False           und          KON   \n",
            "6        nähe     1  VVFIN         52  False           und          KON   \n",
            "7        hohe     1  VVFIN         52  False           und          KON   \n",
            "8        raum     1  VVFIN         52  False           und          KON   \n",
            "9        nähe     2  VVFIN         52  False           die          ART   \n",
            "10        can     2     XY         52  False           die          ART   \n",
            "11      bands     2    ADV         52  False           die          ART   \n",
            "\n",
            "          PLL   PLL norm Number Evaluated Best N Ranking Rating  \\\n",
            "0  -29.300632  -7.325158               10      3       3      1   \n",
            "1  -30.884974  -7.721244               10      3       2      1   \n",
            "2  -30.950538  -6.190108               10      3       1      1   \n",
            "3  -32.395498  -6.479100               20      3       3      1   \n",
            "4  -34.299638  -6.859928               20      3       2      1   \n",
            "5  -37.470257  -7.494051               20      3       1      0   \n",
            "6  -28.673032  -7.168258               10      3       3   None   \n",
            "7  -29.536135  -7.384034               10      3       2   None   \n",
            "8  -31.982967  -7.995742               10      3       1   None   \n",
            "9  -35.332099  -8.833025               10      3       3      1   \n",
            "10 -35.675304 -11.891768               10      3       2      1   \n",
            "11 -43.572317  -8.714463               10      3       1      1   \n",
            "\n",
            "    Evaluation Time  \n",
            "0          0.209223  \n",
            "1          0.209223  \n",
            "2          0.209223  \n",
            "3          0.212399  \n",
            "4          0.212399  \n",
            "5          0.212399  \n",
            "6          0.211124  \n",
            "7          0.211124  \n",
            "8          0.211124  \n",
            "9          0.209111  \n",
            "10         0.209111  \n",
            "11         0.209111  \n",
            "3.2\n",
            "Time to evaluate >10 distractors: 1.0524907112121582\n",
            "Final parameter settings: 3.3000000000000003 0.2\n",
            "Lea und die gehirne [Dozentin]\n",
            "Unacceptable? 0\n",
            "Lea und die Bekämen [Dozentin]\n",
            "Unacceptable? 1\n",
            "Lea und die verhalte [Dozentin]\n",
            "Unacceptable? 1\n",
            "   Distractor Index    POS Sent Index Filler Replaced_Word Replaced_POS  \\\n",
            "0        nähe     1  VVFIN         73  False           und          KON   \n",
            "1        raum     1  VVFIN         73  False           und          KON   \n",
            "2       voran     1  PTKVZ         73  False           und          KON   \n",
            "3       gutem     1  VVFIN         73  False           und          KON   \n",
            "4       weile     1  VVFIN         73  False           und          KON   \n",
            "5       wüste     1  VVFIN         73  False           und          KON   \n",
            "6        nähe     1  VVFIN         52  False           und          KON   \n",
            "7        hohe     1  VVFIN         52  False           und          KON   \n",
            "8        raum     1  VVFIN         52  False           und          KON   \n",
            "9        nähe     2  VVFIN         52  False           die          ART   \n",
            "10        can     2     XY         52  False           die          ART   \n",
            "11      bands     2    ADV         52  False           die          ART   \n",
            "12    gehirne     3   ADJA         52  False      Dozentin           NN   \n",
            "13    Bekämen     3     NN         52  False      Dozentin           NN   \n",
            "14   verhalte     3   ADJA         52  False      Dozentin           NN   \n",
            "\n",
            "          PLL   PLL norm Number Evaluated Best N Ranking Rating  \\\n",
            "0  -29.300632  -7.325158               10      3       3      1   \n",
            "1  -30.884974  -7.721244               10      3       2      1   \n",
            "2  -30.950538  -6.190108               10      3       1      1   \n",
            "3  -32.395498  -6.479100               20      3       3      1   \n",
            "4  -34.299638  -6.859928               20      3       2      1   \n",
            "5  -37.470257  -7.494051               20      3       1      0   \n",
            "6  -28.673032  -7.168258               10      3       3   None   \n",
            "7  -29.536135  -7.384034               10      3       2   None   \n",
            "8  -31.982967  -7.995742               10      3       1   None   \n",
            "9  -35.332099  -8.833025               10      3       3      1   \n",
            "10 -35.675304 -11.891768               10      3       2      1   \n",
            "11 -43.572317  -8.714463               10      3       1      1   \n",
            "12 -37.637471  -5.376782               10      3       3      0   \n",
            "13 -39.225790  -5.603684               10      3       2      1   \n",
            "14 -42.379838  -5.297480               10      3       1      1   \n",
            "\n",
            "    Evaluation Time  \n",
            "0          0.209223  \n",
            "1          0.209223  \n",
            "2          0.209223  \n",
            "3          0.212399  \n",
            "4          0.212399  \n",
            "5          0.212399  \n",
            "6          0.211124  \n",
            "7          0.211124  \n",
            "8          0.211124  \n",
            "9          0.209111  \n",
            "10         0.209111  \n",
            "11         0.209111  \n",
            "12         1.052491  \n",
            "13         1.052491  \n",
            "14         1.052491  \n",
            "6.99\n",
            "Time to evaluate >10 distractors: 0.21299266815185547\n",
            "Final parameter settings: 7.09 0.2\n",
            "Lea und die Dozentin nähe [von]\n",
            "Unacceptable? 1\n",
            "Lea und die Dozentin can [von]\n",
            "Unacceptable? 1\n",
            "Lea und die Dozentin bands [von]\n",
            "Unacceptable? 1\n",
            "   Distractor  Index    POS  Sent Index  Filler Replaced_Word Replaced_POS  \\\n",
            "0        nähe      1  VVFIN          73   False           und          KON   \n",
            "1        raum      1  VVFIN          73   False           und          KON   \n",
            "2       voran      1  PTKVZ          73   False           und          KON   \n",
            "3       gutem      1  VVFIN          73   False           und          KON   \n",
            "4       weile      1  VVFIN          73   False           und          KON   \n",
            "5       wüste      1  VVFIN          73   False           und          KON   \n",
            "6        nähe      1  VVFIN          52   False           und          KON   \n",
            "7        hohe      1  VVFIN          52   False           und          KON   \n",
            "8        raum      1  VVFIN          52   False           und          KON   \n",
            "9        nähe      2  VVFIN          52   False           die          ART   \n",
            "10        can      2     XY          52   False           die          ART   \n",
            "11      bands      2    ADV          52   False           die          ART   \n",
            "12       nähe      4  VVFIN          52   False           von         APPR   \n",
            "13        can      4     XY          52   False           von         APPR   \n",
            "14      bands      4    ADV          52   False           von         APPR   \n",
            "\n",
            "          PLL   PLL norm  Number Evaluated  Best N  Ranking  Rating  \\\n",
            "0  -29.300632  -7.325158                10       3        3     1.0   \n",
            "1  -30.884974  -7.721244                10       3        2     1.0   \n",
            "2  -30.950538  -6.190108                10       3        1     1.0   \n",
            "3  -32.395498  -6.479100                20       3        3     1.0   \n",
            "4  -34.299638  -6.859928                20       3        2     1.0   \n",
            "5  -37.470257  -7.494051                20       3        1     0.0   \n",
            "6  -28.673032  -7.168258                10       3        3     NaN   \n",
            "7  -29.536135  -7.384034                10       3        2     NaN   \n",
            "8  -31.982967  -7.995742                10       3        1     NaN   \n",
            "9  -35.332099  -8.833025                10       3        3     1.0   \n",
            "10 -35.675304 -11.891768                10       3        2     1.0   \n",
            "11 -43.572317  -8.714463                10       3        1     1.0   \n",
            "12 -44.352947 -11.088237                10       3        3     1.0   \n",
            "13 -44.753242 -14.917747                10       3        2     1.0   \n",
            "14 -56.478273 -11.295655                10       3        1     1.0   \n",
            "\n",
            "    Evaluation Time  \n",
            "0          0.209223  \n",
            "1          0.209223  \n",
            "2          0.209223  \n",
            "3          0.212399  \n",
            "4          0.212399  \n",
            "5          0.212399  \n",
            "6          0.211124  \n",
            "7          0.211124  \n",
            "8          0.211124  \n",
            "9          0.209111  \n",
            "10         0.209111  \n",
            "11         0.209111  \n",
            "12         0.212993  \n",
            "13         0.212993  \n",
            "14         0.212993  \n",
            "3.27\n",
            "Time to evaluate >10 distractors: 0.21068048477172852\n",
            "Final parameter settings: 3.37 0.2\n",
            "Lea und die Dozentin von wertungen [Josephine]\n",
            "Unacceptable? 1\n",
            "Lea und die Dozentin von tragenden [Josephine]\n",
            "Unacceptable? 1\n",
            "Lea und die Dozentin von bestimme [Josephine]\n",
            "Unacceptable? 1\n",
            "   Distractor  Index    POS  Sent Index  Filler Replaced_Word Replaced_POS  \\\n",
            "0        nähe      1  VVFIN          73   False           und          KON   \n",
            "1        raum      1  VVFIN          73   False           und          KON   \n",
            "2       voran      1  PTKVZ          73   False           und          KON   \n",
            "3       gutem      1  VVFIN          73   False           und          KON   \n",
            "4       weile      1  VVFIN          73   False           und          KON   \n",
            "5       wüste      1  VVFIN          73   False           und          KON   \n",
            "6        nähe      1  VVFIN          52   False           und          KON   \n",
            "7        hohe      1  VVFIN          52   False           und          KON   \n",
            "8        raum      1  VVFIN          52   False           und          KON   \n",
            "9        nähe      2  VVFIN          52   False           die          ART   \n",
            "10        can      2     XY          52   False           die          ART   \n",
            "11      bands      2    ADV          52   False           die          ART   \n",
            "12    gehirne      3   ADJA          52   False      Dozentin           NN   \n",
            "13    Bekämen      3     NN          52   False      Dozentin           NN   \n",
            "14   verhalte      3   ADJA          52   False      Dozentin           NN   \n",
            "15  wertungen      5  VVFIN          52   False     Josephine           NN   \n",
            "16  tragenden      5  VVFIN          52   False     Josephine           NN   \n",
            "17   bestimme      5  VVFIN          52   False     Josephine           NN   \n",
            "\n",
            "          PLL   PLL norm  Number Evaluated  Best N  Ranking  Rating  \\\n",
            "0  -29.300632  -7.325158                10       3        3     1.0   \n",
            "1  -30.884974  -7.721244                10       3        2     1.0   \n",
            "2  -30.950538  -6.190108                10       3        1     1.0   \n",
            "3  -32.395498  -6.479100                20       3        3     1.0   \n",
            "4  -34.299638  -6.859928                20       3        2     1.0   \n",
            "5  -37.470257  -7.494051                20       3        1     0.0   \n",
            "6  -28.673032  -7.168258                10       3        3     NaN   \n",
            "7  -29.536135  -7.384034                10       3        2     NaN   \n",
            "8  -31.982967  -7.995742                10       3        1     NaN   \n",
            "9  -35.332099  -8.833025                10       3        3     1.0   \n",
            "10 -35.675304 -11.891768                10       3        2     1.0   \n",
            "11 -43.572317  -8.714463                10       3        1     1.0   \n",
            "12 -37.637471  -5.376782                10       3        3     0.0   \n",
            "13 -39.225790  -5.603684                10       3        2     1.0   \n",
            "14 -42.379838  -5.297480                10       3        1     1.0   \n",
            "15 -45.603782  -5.067087                10       3        3     1.0   \n",
            "16 -52.393496  -5.821500                10       3        2     1.0   \n",
            "17 -58.248498  -7.281062                10       3        1     1.0   \n",
            "\n",
            "    Evaluation Time  \n",
            "0          0.209223  \n",
            "1          0.209223  \n",
            "2          0.209223  \n",
            "3          0.212399  \n",
            "4          0.212399  \n",
            "5          0.212399  \n",
            "6          0.211124  \n",
            "7          0.211124  \n",
            "8          0.211124  \n",
            "9          0.209111  \n",
            "10         0.209111  \n",
            "11         0.209111  \n",
            "12         1.052491  \n",
            "13         1.052491  \n",
            "14         1.052491  \n",
            "15         0.210680  \n",
            "16         0.210680  \n",
            "17         0.210680  \n",
            "3.27\n",
            "Time to evaluate >10 distractors: 0.21015620231628418\n",
            "Final parameter settings: 3.37 0.2\n",
            "Lea und die Dozentin von wertungen [Josephine]\n",
            "Unacceptable? 1\n",
            "Lea und die Dozentin von tragenden [Josephine]\n",
            "Unacceptable? 1\n",
            "Lea und die Dozentin von bestimme [Josephine]\n",
            "Unacceptable? 1\n",
            "  Distractor Index    POS Sent Index Filler Replaced_Word Replaced_POS  \\\n",
            "0  wertungen     5  VVFIN         52  False     Josephine           NN   \n",
            "1  tragenden     5  VVFIN         52  False     Josephine           NN   \n",
            "2   bestimme     5  VVFIN         52  False     Josephine           NN   \n",
            "\n",
            "         PLL  PLL norm Number Evaluated Best N Ranking Rating  Evaluation Time  \n",
            "0 -45.603782 -5.067087               10      3       3      1         0.210156  \n",
            "1 -52.393496 -5.821500               10      3       2      1         0.210156  \n",
            "2 -58.248498 -7.281062               10      3       1      1         0.210156  \n",
            "4.16\n",
            "Time to evaluate >10 distractors: 0.39554476737976074\n",
            "Final parameter settings: 4.26 0.2\n",
            "Die anziehen [Flaschen]\n",
            "Unacceptable? 1\n",
            "Die Vorfeld [Flaschen]\n",
            "Unacceptable? 1\n",
            "Die regional [Flaschen]\n",
            "Unacceptable? 1\n",
            "   Distractor  Index    POS  Sent Index  Filler Replaced_Word Replaced_POS  \\\n",
            "0        nähe      1  VVFIN          73   False           und          KON   \n",
            "1        raum      1  VVFIN          73   False           und          KON   \n",
            "2       voran      1  PTKVZ          73   False           und          KON   \n",
            "3       gutem      1  VVFIN          73   False           und          KON   \n",
            "4       weile      1  VVFIN          73   False           und          KON   \n",
            "5       wüste      1  VVFIN          73   False           und          KON   \n",
            "6        nähe      1  VVFIN          52   False           und          KON   \n",
            "7        hohe      1  VVFIN          52   False           und          KON   \n",
            "8        raum      1  VVFIN          52   False           und          KON   \n",
            "9        nähe      2  VVFIN          52   False           die          ART   \n",
            "10        can      2     XY          52   False           die          ART   \n",
            "11      bands      2    ADV          52   False           die          ART   \n",
            "12    gehirne      3   ADJA          52   False      Dozentin           NN   \n",
            "13    Bekämen      3     NN          52   False      Dozentin           NN   \n",
            "14   verhalte      3   ADJA          52   False      Dozentin           NN   \n",
            "15  wertungen      5  VVFIN          52   False     Josephine           NN   \n",
            "16  tragenden      5  VVFIN          52   False     Josephine           NN   \n",
            "17   bestimme      5  VVFIN          52   False     Josephine           NN   \n",
            "18   anziehen      1   ADJA          52    True      Flaschen           NN   \n",
            "19    Vorfeld      1     NN          52    True      Flaschen           NN   \n",
            "20   regional      1   ADJD          52    True      Flaschen           NN   \n",
            "\n",
            "          PLL   PLL norm  Number Evaluated  Best N  Ranking  Rating  \\\n",
            "0  -29.300632  -7.325158                10       3        3     1.0   \n",
            "1  -30.884974  -7.721244                10       3        2     1.0   \n",
            "2  -30.950538  -6.190108                10       3        1     1.0   \n",
            "3  -32.395498  -6.479100                20       3        3     1.0   \n",
            "4  -34.299638  -6.859928                20       3        2     1.0   \n",
            "5  -37.470257  -7.494051                20       3        1     0.0   \n",
            "6  -28.673032  -7.168258                10       3        3     NaN   \n",
            "7  -29.536135  -7.384034                10       3        2     NaN   \n",
            "8  -31.982967  -7.995742                10       3        1     NaN   \n",
            "9  -35.332099  -8.833025                10       3        3     1.0   \n",
            "10 -35.675304 -11.891768                10       3        2     1.0   \n",
            "11 -43.572317  -8.714463                10       3        1     1.0   \n",
            "12 -37.637471  -5.376782                10       3        3     0.0   \n",
            "13 -39.225790  -5.603684                10       3        2     1.0   \n",
            "14 -42.379838  -5.297480                10       3        1     1.0   \n",
            "15 -45.603782  -5.067087                10       3        3     1.0   \n",
            "16 -52.393496  -5.821500                10       3        2     1.0   \n",
            "17 -58.248498  -7.281062                10       3        1     1.0   \n",
            "18 -20.902901  -2.612863                10       3        3     1.0   \n",
            "19 -21.342859  -3.048980                10       3        2     1.0   \n",
            "20 -21.964370  -2.745546                10       3        1     1.0   \n",
            "\n",
            "    Evaluation Time  \n",
            "0          0.209223  \n",
            "1          0.209223  \n",
            "2          0.209223  \n",
            "3          0.212399  \n",
            "4          0.212399  \n",
            "5          0.212399  \n",
            "6          0.211124  \n",
            "7          0.211124  \n",
            "8          0.211124  \n",
            "9          0.209111  \n",
            "10         0.209111  \n",
            "11         0.209111  \n",
            "12         1.052491  \n",
            "13         1.052491  \n",
            "14         1.052491  \n",
            "15         0.210680  \n",
            "16         0.210680  \n",
            "17         0.210680  \n",
            "18         0.395545  \n",
            "19         0.395545  \n",
            "20         0.395545  \n",
            "4.16\n",
            "Time to evaluate >10 distractors: 0.41455864906311035\n",
            "Final parameter settings: 4.26 0.2\n",
            "Distractor regional already rated 1.0\n",
            "Die reiches [Flaschen]\n",
            "Unacceptable? 1\n",
            "Die schonmal [Flaschen]\n",
            "Unacceptable? 0\n",
            "   Distractor  Index    POS  Sent Index  Filler Replaced_Word Replaced_POS  \\\n",
            "0        nähe      1  VVFIN          73   False           und          KON   \n",
            "1        raum      1  VVFIN          73   False           und          KON   \n",
            "2       voran      1  PTKVZ          73   False           und          KON   \n",
            "3       gutem      1  VVFIN          73   False           und          KON   \n",
            "4       weile      1  VVFIN          73   False           und          KON   \n",
            "5       wüste      1  VVFIN          73   False           und          KON   \n",
            "6        nähe      1  VVFIN          52   False           und          KON   \n",
            "7        hohe      1  VVFIN          52   False           und          KON   \n",
            "8        raum      1  VVFIN          52   False           und          KON   \n",
            "9        nähe      2  VVFIN          52   False           die          ART   \n",
            "10        can      2     XY          52   False           die          ART   \n",
            "11      bands      2    ADV          52   False           die          ART   \n",
            "12    gehirne      3   ADJA          52   False      Dozentin           NN   \n",
            "13    Bekämen      3     NN          52   False      Dozentin           NN   \n",
            "14   verhalte      3   ADJA          52   False      Dozentin           NN   \n",
            "15  wertungen      5  VVFIN          52   False     Josephine           NN   \n",
            "16  tragenden      5  VVFIN          52   False     Josephine           NN   \n",
            "17   bestimme      5  VVFIN          52   False     Josephine           NN   \n",
            "18   anziehen      1   ADJA          52    True      Flaschen           NN   \n",
            "19    Vorfeld      1     NN          52    True      Flaschen           NN   \n",
            "20   regional      1   ADJD          52    True      Flaschen           NN   \n",
            "21   regional      1   ADJD          52    True      Flaschen           NN   \n",
            "22    reiches      1   ADJA          52    True      Flaschen           NN   \n",
            "23   schonmal      1    ADV          52    True      Flaschen           NN   \n",
            "\n",
            "          PLL   PLL norm  Number Evaluated  Best N  Ranking  Rating  \\\n",
            "0  -29.300632  -7.325158                10       3        3     1.0   \n",
            "1  -30.884974  -7.721244                10       3        2     1.0   \n",
            "2  -30.950538  -6.190108                10       3        1     1.0   \n",
            "3  -32.395498  -6.479100                20       3        3     1.0   \n",
            "4  -34.299638  -6.859928                20       3        2     1.0   \n",
            "5  -37.470257  -7.494051                20       3        1     0.0   \n",
            "6  -28.673032  -7.168258                10       3        3     NaN   \n",
            "7  -29.536135  -7.384034                10       3        2     NaN   \n",
            "8  -31.982967  -7.995742                10       3        1     NaN   \n",
            "9  -35.332099  -8.833025                10       3        3     1.0   \n",
            "10 -35.675304 -11.891768                10       3        2     1.0   \n",
            "11 -43.572317  -8.714463                10       3        1     1.0   \n",
            "12 -37.637471  -5.376782                10       3        3     0.0   \n",
            "13 -39.225790  -5.603684                10       3        2     1.0   \n",
            "14 -42.379838  -5.297480                10       3        1     1.0   \n",
            "15 -45.603782  -5.067087                10       3        3     1.0   \n",
            "16 -52.393496  -5.821500                10       3        2     1.0   \n",
            "17 -58.248498  -7.281062                10       3        1     1.0   \n",
            "18 -20.902901  -2.612863                10       3        3     1.0   \n",
            "19 -21.342859  -3.048980                10       3        2     1.0   \n",
            "20 -21.964370  -2.745546                10       3        1     1.0   \n",
            "21 -66.191193  -8.273899                10       3        3     1.0   \n",
            "22 -69.762763  -9.966109                10       3        2     1.0   \n",
            "23 -73.450723  -9.181340                10       3        1     0.0   \n",
            "\n",
            "    Evaluation Time  \n",
            "0          0.209223  \n",
            "1          0.209223  \n",
            "2          0.209223  \n",
            "3          0.212399  \n",
            "4          0.212399  \n",
            "5          0.212399  \n",
            "6          0.211124  \n",
            "7          0.211124  \n",
            "8          0.211124  \n",
            "9          0.209111  \n",
            "10         0.209111  \n",
            "11         0.209111  \n",
            "12         1.052491  \n",
            "13         1.052491  \n",
            "14         1.052491  \n",
            "15         0.210680  \n",
            "16         0.210680  \n",
            "17         0.210680  \n",
            "18         0.395545  \n",
            "19         0.395545  \n",
            "20         0.395545  \n",
            "21         0.414559  \n",
            "22         0.414559  \n",
            "23         0.414559  \n",
            "80\n",
            "All the following should be true if we're not mutating anything that we shouldn't be.\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "#Testing save_top_distractors through batch_eval\n",
        "sent_ind = np.random.randint(0,90)\n",
        "test_sent = exp_sent_lists[sent_ind]\n",
        "dist_ind = 1\n",
        "new_df = test.batch_eval(dist_ind,test_sent,sent_ind,10,3)\n",
        "#just reevaluating with more distractors - shouldn't make us rate the distractors again even without the multi parameter\n",
        "print(\"Some of these probably won't be new...\")\n",
        "new_df = test.batch_eval(dist_ind,test_sent,sent_ind,20,3,dist_df=new_df)\n",
        "#appending but with a different sentence this time\n",
        "sent_ind = np.random.randint(0,90)\n",
        "test_sent = exp_sent_lists[sent_ind]\n",
        "#rate set to false\n",
        "new_df = test.batch_eval(dist_ind,test_sent,sent_ind,10,3,dist_df=new_df,rate=False)\n",
        "print(new_df)\n",
        "#Saving in a csv\n",
        "dist_ind = 2\n",
        "new_df = test.batch_eval(dist_ind,test_sent,sent_ind,10,3,dist_df=new_df,save_csv=True)\n",
        "print(new_df)\n",
        "dist_ind = 3 \n",
        "dumb_test_name = \"ToTestNamingDistractorFile.csv\"\n",
        "new_df = test.batch_eval(dist_ind,test_sent,sent_ind,10,3,dist_df=new_df,save_csv=dumb_test_name)\n",
        "print(new_df)\n",
        "#Appending to data in csv\n",
        "dist_ind = 4\n",
        "new_df = test.batch_eval(dist_ind,test_sent,sent_ind,10,3,dist_csv=\"DistractorRecord.csv\")\n",
        "print(new_df)\n",
        "dist_ind = 5\n",
        "new_df = test.batch_eval(dist_ind,test_sent,sent_ind,10,3,dist_csv=dumb_test_name)\n",
        "print(new_df)\n",
        "#Tagged set to false\n",
        "print(test.batch_eval(dist_ind,test_sent,sent_ind,10,3,tagged=False))\n",
        "#Pass a filler\n",
        "dist_ind = 1\n",
        "test_sent = filler_sent_lists[sent_ind]\n",
        "new_df = test.batch_eval(dist_ind,test_sent,sent_ind,10,3,filler=True,dist_df=new_df)\n",
        "print(new_df)\n",
        "#just_preceding set to false\n",
        "#the same distractors with the same PLLS and wrong POS tags for both - suggests that this doesn't work\n",
        "print(test.batch_eval(dist_ind,test_sent,sent_ind,10,3,filler=True,just_preceding=False,dist_df=new_df))\n",
        "\n",
        "print(len(test.dists_dict))\n",
        "print(\"All the following should be true if we're not mutating anything that we shouldn't be.\")\n",
        "#print(test_sent == test_sent_copy) #actually this one should be false because we've since changed the test_sent and not copied it hehe\n",
        "print(test.nonwords_set == nonwords_set_copy)\n",
        "print(test.word_info == word_info_copy)\n",
        "print(test.freq_dict == freq_dict_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKKgbxHsmzmv",
        "outputId": "f9518c5c-343f-448e-d3ff-91b6264fcf3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lea nähe [und]\n",
            "Unacceptable? 1\n",
            "Lea hohe [und]\n",
            "Unacceptable? 1\n",
            "Lea raum [und]\n",
            "Unacceptable? 1\n",
            "   Distractor  Index    POS  Sent Index  Filler Replaced_Word Replaced_POS  \\\n",
            "0        nähe      1  VVFIN          73   False           und          KON   \n",
            "1        raum      1  VVFIN          73   False           und          KON   \n",
            "2       voran      1  PTKVZ          73   False           und          KON   \n",
            "3       gutem      1  VVFIN          73   False           und          KON   \n",
            "4       weile      1  VVFIN          73   False           und          KON   \n",
            "5       wüste      1  VVFIN          73   False           und          KON   \n",
            "6        nähe      1  VVFIN          52   False           und          KON   \n",
            "7        hohe      1  VVFIN          52   False           und          KON   \n",
            "8        raum      1  VVFIN          52   False           und          KON   \n",
            "9        nähe      2  VVFIN          52   False           die          ART   \n",
            "10        can      2     XY          52   False           die          ART   \n",
            "11      bands      2    ADV          52   False           die          ART   \n",
            "12    gehirne      3   ADJA          52   False      Dozentin           NN   \n",
            "13    Bekämen      3     NN          52   False      Dozentin           NN   \n",
            "14   verhalte      3   ADJA          52   False      Dozentin           NN   \n",
            "15  wertungen      5  VVFIN          52   False     Josephine           NN   \n",
            "16  tragenden      5  VVFIN          52   False     Josephine           NN   \n",
            "17   bestimme      5  VVFIN          52   False     Josephine           NN   \n",
            "18   anziehen      1   ADJA          52    True      Flaschen           NN   \n",
            "19    Vorfeld      1     NN          52    True      Flaschen           NN   \n",
            "20   regional      1   ADJD          52    True      Flaschen           NN   \n",
            "21   regional      1   ADJD          52    True      Flaschen           NN   \n",
            "22    reiches      1   ADJA          52    True      Flaschen           NN   \n",
            "23   schonmal      1    ADV          52    True      Flaschen           NN   \n",
            "\n",
            "          PLL   PLL norm  Number Evaluated  Best N  Ranking  Rating  \\\n",
            "0  -29.300632  -7.325158                10       3        3     1.0   \n",
            "1  -30.884974  -7.721244                10       3        2     1.0   \n",
            "2  -30.950538  -6.190108                10       3        1     1.0   \n",
            "3  -32.395498  -6.479100                20       3        3     1.0   \n",
            "4  -34.299638  -6.859928                20       3        2     1.0   \n",
            "5  -37.470257  -7.494051                20       3        1     0.0   \n",
            "6  -28.673032  -7.168258                10       3        3     1.0   \n",
            "7  -29.536135  -7.384034                10       3        2     1.0   \n",
            "8  -31.982967  -7.995742                10       3        1     1.0   \n",
            "9  -35.332099  -8.833025                10       3        3     1.0   \n",
            "10 -35.675304 -11.891768                10       3        2     1.0   \n",
            "11 -43.572317  -8.714463                10       3        1     1.0   \n",
            "12 -37.637471  -5.376782                10       3        3     0.0   \n",
            "13 -39.225790  -5.603684                10       3        2     1.0   \n",
            "14 -42.379838  -5.297480                10       3        1     1.0   \n",
            "15 -45.603782  -5.067087                10       3        3     1.0   \n",
            "16 -52.393496  -5.821500                10       3        2     1.0   \n",
            "17 -58.248498  -7.281062                10       3        1     1.0   \n",
            "18 -20.902901  -2.612863                10       3        3     1.0   \n",
            "19 -21.342859  -3.048980                10       3        2     1.0   \n",
            "20 -21.964370  -2.745546                10       3        1     1.0   \n",
            "21 -66.191193  -8.273899                10       3        3     1.0   \n",
            "22 -69.762763  -9.966109                10       3        2     1.0   \n",
            "23 -73.450723  -9.181340                10       3        1     0.0   \n",
            "\n",
            "    Evaluation Time  \n",
            "0          0.209223  \n",
            "1          0.209223  \n",
            "2          0.209223  \n",
            "3          0.212399  \n",
            "4          0.212399  \n",
            "5          0.212399  \n",
            "6          0.211124  \n",
            "7          0.211124  \n",
            "8          0.211124  \n",
            "9          0.209111  \n",
            "10         0.209111  \n",
            "11         0.209111  \n",
            "12         1.052491  \n",
            "13         1.052491  \n",
            "14         1.052491  \n",
            "15         0.210680  \n",
            "16         0.210680  \n",
            "17         0.210680  \n",
            "18         0.395545  \n",
            "19         0.395545  \n",
            "20         0.395545  \n",
            "21         0.414559  \n",
            "22         0.414559  \n",
            "23         0.414559  \n",
            "True\n",
            "True\n",
            "3.49\n",
            "Time to evaluate >10 distractors: 0.6920115947723389\n",
            "Final parameter settings: 3.5900000000000003 0.2\n",
            "  Distractor Index    POS Sent Index Filler Replaced_Word Replaced_POS  \\\n",
            "0   befehlen     1  VVFIN         63  False      Anwältin           NN   \n",
            "1   bestelle     1   ADJA         63  False      Anwältin           NN   \n",
            "2    gerannt     1   VVPP         63  False      Anwältin           NN   \n",
            "\n",
            "         PLL  PLL norm Number Evaluated Best N Ranking Rating  Evaluation Time  \n",
            "0 -22.394178 -2.799272               10      3       3   None         0.692012  \n",
            "1 -24.035098 -3.004387               10      3       2   None         0.692012  \n",
            "2 -27.610724 -3.944389               10      3       1   None         0.692012  \n",
            "Die befehlen [Anwältin]\n",
            "Unacceptable? 1\n",
            "Die bestelle [Anwältin]\n",
            "Unacceptable? 1\n",
            "Die gerannt [Anwältin]\n",
            "Unacceptable? 1\n",
            "  Distractor Index    POS Sent Index Filler Replaced_Word Replaced_POS  \\\n",
            "0   befehlen     1  VVFIN         63  False      Anwältin           NN   \n",
            "1   bestelle     1   ADJA         63  False      Anwältin           NN   \n",
            "2    gerannt     1   VVPP         63  False      Anwältin           NN   \n",
            "\n",
            "         PLL  PLL norm Number Evaluated Best N Ranking Rating  Evaluation Time  \n",
            "0 -22.394178 -2.799272               10      3       3      1         0.692012  \n",
            "1 -24.035098 -3.004387               10      3       2      1         0.692012  \n",
            "2 -27.610724 -3.944389               10      3       1      1         0.692012  \n",
            "True\n",
            "True\n",
            "7.42\n",
            "Time to evaluate >10 distractors: 0.21087193489074707\n",
            "Final parameter settings: 7.52 0.2\n",
            "Heike nähe [und]\n",
            "Unacceptable? 1\n",
            "Heike hohe [und]\n",
            "Unacceptable? 1\n",
            "Heike voran [und]\n",
            "Unacceptable? 1\n",
            "  Distractor Index    POS Sent Index Filler Replaced_Word Replaced_POS  \\\n",
            "0       nähe     1  VVFIN         55  False           und          KON   \n",
            "1       hohe     1  VVFIN         55  False           und          KON   \n",
            "2      voran     1  PTKVZ         55  False           und          KON   \n",
            "\n",
            "         PLL  PLL norm Number Evaluated Best N Ranking Rating  Evaluation Time  \n",
            "0 -25.217139 -6.304285               10      3       3      1         0.210872  \n",
            "1 -25.716523 -6.429131               10      3       2      1         0.210872  \n",
            "2 -26.923464 -5.384693               10      3       1      1         0.210872  \n",
            "True\n",
            "True\n",
            "   Distractor  Index    POS  Sent Index  Filler Replaced_Word Replaced_POS  \\\n",
            "0        nähe      1  VVFIN          73   False           und          KON   \n",
            "1        raum      1  VVFIN          73   False           und          KON   \n",
            "2       voran      1  PTKVZ          73   False           und          KON   \n",
            "3       gutem      1  VVFIN          73   False           und          KON   \n",
            "4       weile      1  VVFIN          73   False           und          KON   \n",
            "5       wüste      1  VVFIN          73   False           und          KON   \n",
            "6        nähe      1  VVFIN          52   False           und          KON   \n",
            "7        hohe      1  VVFIN          52   False           und          KON   \n",
            "8        raum      1  VVFIN          52   False           und          KON   \n",
            "9        nähe      2  VVFIN          52   False           die          ART   \n",
            "10        can      2     XY          52   False           die          ART   \n",
            "11      bands      2    ADV          52   False           die          ART   \n",
            "12    gehirne      3   ADJA          52   False      Dozentin           NN   \n",
            "13    Bekämen      3     NN          52   False      Dozentin           NN   \n",
            "14   verhalte      3   ADJA          52   False      Dozentin           NN   \n",
            "15  wertungen      5  VVFIN          52   False     Josephine           NN   \n",
            "16  tragenden      5  VVFIN          52   False     Josephine           NN   \n",
            "17   bestimme      5  VVFIN          52   False     Josephine           NN   \n",
            "18   anziehen      1   ADJA          52    True      Flaschen           NN   \n",
            "19    Vorfeld      1     NN          52    True      Flaschen           NN   \n",
            "20   regional      1   ADJD          52    True      Flaschen           NN   \n",
            "21   regional      1   ADJD          52    True      Flaschen           NN   \n",
            "22    reiches      1   ADJA          52    True      Flaschen           NN   \n",
            "23   schonmal      1    ADV          52    True      Flaschen           NN   \n",
            "\n",
            "          PLL   PLL norm  Number Evaluated  Best N  Ranking  Rating  \\\n",
            "0  -29.300632  -7.325158                10       3        3     1.0   \n",
            "1  -30.884974  -7.721244                10       3        2     1.0   \n",
            "2  -30.950538  -6.190108                10       3        1     1.0   \n",
            "3  -32.395498  -6.479100                20       3        3     1.0   \n",
            "4  -34.299638  -6.859928                20       3        2     1.0   \n",
            "5  -37.470257  -7.494051                20       3        1     0.0   \n",
            "6  -28.673032  -7.168258                10       3        3     1.0   \n",
            "7  -29.536135  -7.384034                10       3        2     1.0   \n",
            "8  -31.982967  -7.995742                10       3        1     1.0   \n",
            "9  -35.332099  -8.833025                10       3        3     1.0   \n",
            "10 -35.675304 -11.891768                10       3        2     1.0   \n",
            "11 -43.572317  -8.714463                10       3        1     1.0   \n",
            "12 -37.637471  -5.376782                10       3        3     0.0   \n",
            "13 -39.225790  -5.603684                10       3        2     1.0   \n",
            "14 -42.379838  -5.297480                10       3        1     1.0   \n",
            "15 -45.603782  -5.067087                10       3        3     1.0   \n",
            "16 -52.393496  -5.821500                10       3        2     1.0   \n",
            "17 -58.248498  -7.281062                10       3        1     1.0   \n",
            "18 -20.902901  -2.612863                10       3        3     1.0   \n",
            "19 -21.342859  -3.048980                10       3        2     1.0   \n",
            "20 -21.964370  -2.745546                10       3        1     1.0   \n",
            "21 -66.191193  -8.273899                10       3        3     1.0   \n",
            "22 -69.762763  -9.966109                10       3        2     1.0   \n",
            "23 -73.450723  -9.181340                10       3        1     0.0   \n",
            "\n",
            "    Evaluation Time  \n",
            "0          0.209223  \n",
            "1          0.209223  \n",
            "2          0.209223  \n",
            "3          0.212399  \n",
            "4          0.212399  \n",
            "5          0.212399  \n",
            "6          0.211124  \n",
            "7          0.211124  \n",
            "8          0.211124  \n",
            "9          0.209111  \n",
            "10         0.209111  \n",
            "11         0.209111  \n",
            "12         1.052491  \n",
            "13         1.052491  \n",
            "14         1.052491  \n",
            "15         0.210680  \n",
            "16         0.210680  \n",
            "17         0.210680  \n",
            "18         0.395545  \n",
            "19         0.395545  \n",
            "20         0.395545  \n",
            "21         0.414559  \n",
            "22         0.414559  \n",
            "23         0.414559  \n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "#add_rating testing on already existing \n",
        "new_df = test.add_ratings(new_df,exp_sent_lists,filler_sent_lists)\n",
        "print(new_df)\n",
        "print(exp_sent_lists == exp_sent_lists_copy)\n",
        "print(filler_sent_lists == filler_sent_lists_copy)\n",
        "\n",
        "#when adding straight to a dataframe not coming from a csv\n",
        "sent_ind = np.random.randint(0,90)\n",
        "test_sent = exp_sent_lists[sent_ind]\n",
        "newer_df = test.batch_eval(dist_ind,test_sent,sent_ind,10,3,rate=False)\n",
        "print(newer_df)\n",
        "newer_df = test.add_ratings(newer_df,exp_sent_lists,filler_sent_lists)\n",
        "print(newer_df)\n",
        "print(exp_sent_lists == exp_sent_lists_copy)\n",
        "print(filler_sent_lists == filler_sent_lists_copy)\n",
        "\n",
        "#adding to a saved csv\n",
        "sent_ind = np.random.randint(0,90)\n",
        "test_sent = exp_sent_lists[sent_ind]\n",
        "newest_df = test.batch_eval(dist_ind,test_sent,sent_ind,10,3,rate=False,save_csv=dumb_test_name)\n",
        "print(test.add_ratings(newest_df,exp_sent_lists,filler_sent_lists))\n",
        "print(exp_sent_lists == exp_sent_lists_copy)\n",
        "print(filler_sent_lists == filler_sent_lists_copy)\n",
        "\n",
        "#nothing should happen here\n",
        "print(test.add_ratings(new_df,exp_sent_lists,filler_sent_lists))\n",
        "print(exp_sent_lists == exp_sent_lists_copy)\n",
        "print(filler_sent_lists == filler_sent_lists_copy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4UCr7GnUqoI"
      },
      "source": [
        "Parameters to test:\n",
        "* start_ind\n",
        "  * valid value\n",
        "  * invalid value\n",
        "* end_ind \n",
        "  * valid value\n",
        "  * invalid value\n",
        "\n",
        "Plugged into batch_eval and therefore already tested:\n",
        "* tagged\n",
        "* use_tag\n",
        "* filler\n",
        "* just_preceding\n",
        "* rate\n",
        "* dist_df\n",
        "* dist_csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzVcnW-YUfp4",
        "outputId": "619c77cb-9a31-427c-f8e1-1c71e886f754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "Round 1/24: Find distractor for word at index 1 by comparing 10 potential distractors\n",
            "3.71\n",
            "Time to evaluate >10 distractors: 0.6634187698364258\n",
            "Final parameter settings: 3.81 0.2\n",
            "Thomas überdenken [beobachtete]\n",
            "Unacceptable? 1\n",
            "Thomas instrumenten [beobachtete]\n",
            "Unacceptable? 1\n",
            "Thomas festzuhalten [beobachtete]\n",
            "Unacceptable? 0\n",
            "Round 2/24: Find distractor for word at index 1 by comparing 20 potential distractors\n",
            "3.71\n",
            "Time to evaluate >20 distractors: 0.21275734901428223\n",
            "Final parameter settings: 3.81 0.2\n",
            "Distractor instrumenten already rated 1\n",
            "Thomas medikamenten [beobachtete]\n",
            "Unacceptable? 1\n",
            "Thomas radfahren [beobachtete]\n",
            "Unacceptable? 0\n",
            "Round 3/24: Find distractor for word at index 1 by comparing 30 potential distractors\n",
            "3.71\n",
            "Time to evaluate >30 distractors: 0.3139307498931885\n",
            "Final parameter settings: 3.81 0.2\n",
            "Distractor festzuhalten already rated 0\n",
            "Distractor medikamenten already rated 1\n",
            "Distractor radfahren already rated 0\n",
            "Round 4/24: Find distractor for word at index 2 by comparing 10 potential distractors\n",
            "5.72\n",
            "Time to evaluate >10 distractors: 0.5088539123535156\n",
            "Final parameter settings: 5.819999999999999 0.2\n",
            "Thomas beobachtete Mann [seinen]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete hätte [seinen]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete bitte [seinen]\n",
            "Unacceptable? 1\n",
            "Round 5/24: Find distractor for word at index 2 by comparing 20 potential distractors\n",
            "5.72\n",
            "Time to evaluate >20 distractors: 0.47832226753234863\n",
            "Final parameter settings: 5.819999999999999 0.2\n",
            "Thomas beobachtete andere [seinen]\n",
            "Unacceptable? 0\n",
            "Thomas beobachtete warum [seinen]\n",
            "Unacceptable? 0\n",
            "Thomas beobachtete sowie [seinen]\n",
            "Unacceptable? 0\n",
            "Round 6/24: Find distractor for word at index 2 by comparing 30 potential distractors\n",
            "5.72\n",
            "Time to evaluate >30 distractors: 0.5966429710388184\n",
            "Final parameter settings: 5.819999999999999 0.2\n",
            "Distractor andere already rated 0\n",
            "Distractor warum already rated 0\n",
            "Distractor sowie already rated 0\n",
            "Round 7/24: Find distractor for word at index 3 by comparing 10 potential distractors\n",
            "4.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluonnlp/data/sampler.py:354: UserWarning: Some buckets are empty and will be removed. Unused bucket keys=[8]\n",
            "  str(unused_bucket_keys))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to evaluate >10 distractors: 0.24312782287597656\n",
            "Final parameter settings: 4.71 0.2\n",
            "Thomas beobachtete seinen Analyse [Nachbarn]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen getötet [Nachbarn]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen aussagen [Nachbarn]\n",
            "Unacceptable? 1\n",
            "Round 8/24: Find distractor for word at index 3 by comparing 20 potential distractors\n",
            "4.61\n",
            "Time to evaluate >20 distractors: 0.31321024894714355\n",
            "Final parameter settings: 4.71 0.2\n",
            "Distractor aussagen already rated 1\n",
            "Thomas beobachtete seinen erfüllt [Nachbarn]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Weshalb [Nachbarn]\n",
            "Unacceptable? 1\n",
            "Round 9/24: Find distractor for word at index 3 by comparing 30 potential distractors\n",
            "4.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluonnlp/data/sampler.py:354: UserWarning: Some buckets are empty and will be removed. Unused bucket keys=[8, 9]\n",
            "  str(unused_bucket_keys))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to evaluate >30 distractors: 0.6227614879608154\n",
            "Final parameter settings: 4.71 0.2\n",
            "Distractor aussagen already rated 1\n",
            "Distractor erfüllt already rated 1\n",
            "Distractor Weshalb already rated 1\n",
            "Round 10/24: Find distractor for word at index 4 by comparing 10 potential distractors\n",
            "5.11\n",
            "Time to evaluate >10 distractors: 0.4307096004486084\n",
            "Final parameter settings: 5.21 0.2\n",
            "Thomas beobachtete seinen Nachbarn august, [Peter,]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn mitte, [Peter,]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn Raum, [Peter,]\n",
            "Unacceptable? 1\n",
            "Round 11/24: Find distractor for word at index 4 by comparing 20 potential distractors\n",
            "5.11\n",
            "Time to evaluate >20 distractors: 0.6459290981292725\n",
            "Final parameter settings: 5.21 0.2\n",
            "Thomas beobachtete seinen Nachbarn dachte, [Peter,]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn mach, [Peter,]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn setzen, [Peter,]\n",
            "Unacceptable? 1\n",
            "Round 12/24: Find distractor for word at index 4 by comparing 30 potential distractors\n",
            "5.11\n",
            "Time to evaluate >30 distractors: 0.21605443954467773\n",
            "Final parameter settings: 5.21 0.2\n",
            "Thomas beobachtete seinen Nachbarn hält, [Peter,]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn sachen, [Peter,]\n",
            "Unacceptable? 0\n",
            "Distractor setzen already rated 1\n",
            "Round 13/24: Find distractor for word at index 5 by comparing 10 potential distractors\n",
            "7.46\n",
            "Time to evaluate >10 distractors: 0.9329886436462402\n",
            "Final parameter settings: 7.959999999999998 0.28\n",
            "Thomas beobachtete seinen Nachbarn Peter, nicht [der]\n",
            "Unacceptable? 0\n",
            "Thomas beobachtete seinen Nachbarn Peter, ist [der]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn Peter, ich [der]\n",
            "Unacceptable? 1\n",
            "Round 14/24: Find distractor for word at index 5 by comparing 20 potential distractors\n",
            "7.46\n",
            "Time to evaluate >20 distractors: 1.2459383010864258\n",
            "Final parameter settings: 8.159999999999998 0.32000000000000006\n",
            "Thomas beobachtete seinen Nachbarn Peter, auf [der]\n",
            "Unacceptable? 0\n",
            "Thomas beobachtete seinen Nachbarn Peter, sich [der]\n",
            "Unacceptable? 0\n",
            "Thomas beobachtete seinen Nachbarn Peter, im [der]\n",
            "Unacceptable? 0\n",
            "Round 15/24: Find distractor for word at index 5 by comparing 30 potential distractors\n",
            "7.46\n",
            "Time to evaluate >30 distractors: 1.1576972007751465\n",
            "Final parameter settings: 8.359999999999998 0.3600000000000001\n",
            "Distractor sich already rated 0\n",
            "Thomas beobachtete seinen Nachbarn Peter, an [der]\n",
            "Unacceptable? 0\n",
            "Distractor im already rated 0\n",
            "Round 16/24: Find distractor for word at index 6 by comparing 10 potential distractors\n",
            "5.72\n",
            "Time to evaluate >10 distractors: 0.21283507347106934\n",
            "Final parameter settings: 5.819999999999999 0.2\n",
            "Thomas beobachtete seinen Nachbarn Peter, der weiter [seinen]\n",
            "Unacceptable? 0\n",
            "Thomas beobachtete seinen Nachbarn Peter, der hast [seinen]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn Peter, der lassen [seinen]\n",
            "Unacceptable? 1\n",
            "Round 17/24: Find distractor for word at index 6 by comparing 20 potential distractors\n",
            "5.72\n",
            "Time to evaluate >20 distractors: 0.21370768547058105\n",
            "Final parameter settings: 5.819999999999999 0.2\n",
            "Thomas beobachtete seinen Nachbarn Peter, der ihnen [seinen]\n",
            "Unacceptable? 0\n",
            "Thomas beobachtete seinen Nachbarn Peter, der warum [seinen]\n",
            "Unacceptable? 1\n",
            "Distractor lassen already rated 1\n",
            "Round 18/24: Find distractor for word at index 6 by comparing 30 potential distractors\n",
            "5.72\n",
            "Time to evaluate >30 distractors: 0.3331172466278076\n",
            "Final parameter settings: 5.819999999999999 0.2\n",
            "Thomas beobachtete seinen Nachbarn Peter, der wollen [seinen]\n",
            "Unacceptable? 1\n",
            "Distractor warum already rated 1\n",
            "Distractor lassen already rated 1\n",
            "Round 19/24: Find distractor for word at index 7 by comparing 10 potential distractors\n",
            "2.81\n",
            "Time to evaluate >10 distractors: 1.870877981185913\n",
            "Final parameter settings: 2.91 0.2\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Provokante [Gartenzaun]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Zeitbombe [Gartenzaun]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Masseinheit [Gartenzaun]\n",
            "Unacceptable? 1\n",
            "Round 20/24: Find distractor for word at index 7 by comparing 20 potential distractors\n",
            "2.81\n",
            "Time to evaluate >20 distractors: 0.31673526763916016\n",
            "Final parameter settings: 2.91 0.2\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen schmunzelnd [Gartenzaun]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Kulturgüter [Gartenzaun]\n",
            "Unacceptable? 0\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Rheinberg [Gartenzaun]\n",
            "Unacceptable? 1\n",
            "Round 21/24: Find distractor for word at index 7 by comparing 30 potential distractors\n",
            "2.81\n",
            "Time to evaluate >30 distractors: 0.41957831382751465\n",
            "Final parameter settings: 2.91 0.2\n",
            "Distractor Rheinberg already rated 1\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Seitenzahl [Gartenzaun]\n",
            "Unacceptable? 0\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Notlandung [Gartenzaun]\n",
            "Unacceptable? 1\n",
            "Round 22/24: Find distractor for word at index 8 by comparing 10 potential distractors\n",
            "4.18\n",
            "Time to evaluate >10 distractors: 0.42583703994750977\n",
            "Final parameter settings: 4.279999999999999 0.2\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Gartenzaun profis. [strich.]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Gartenzaun traten. [strich.]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Gartenzaun Bündnis. [strich.]\n",
            "Unacceptable? 1\n",
            "Round 23/24: Find distractor for word at index 8 by comparing 20 potential distractors\n",
            "4.18\n",
            "Time to evaluate >20 distractors: 0.31770753860473633\n",
            "Final parameter settings: 4.279999999999999 0.2\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Gartenzaun ferien. [strich.]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Gartenzaun volkes. [strich.]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn Peter, der seinen Gartenzaun konrad. [strich.]\n",
            "Unacceptable? 1\n",
            "Round 24/24: Find distractor for word at index 8 by comparing 30 potential distractors\n",
            "4.18\n",
            "Time to evaluate >30 distractors: 0.5566375255584717\n",
            "Final parameter settings: 4.279999999999999 0.2\n",
            "Distractor volkes already rated 1\n",
            "Distractor konrad already rated 1\n",
            "Distractor Bündnis already rated 1\n",
            "      Distractor Index    POS Sent Index Filler Replaced_Word Replaced_POS  \\\n",
            "0     überdenken     1  VVINF          0   True   beobachtete        VVFIN   \n",
            "1   instrumenten     1  VVFIN          0   True   beobachtete        VVFIN   \n",
            "2   festzuhalten     1  VVIZU          0   True   beobachtete        VVFIN   \n",
            "3   instrumenten     1  VVFIN          0   True   beobachtete        VVFIN   \n",
            "4   medikamenten     1  VVFIN          0   True   beobachtete        VVFIN   \n",
            "..           ...   ...    ...        ...    ...           ...          ...   \n",
            "67        volkes     8  VVFIN          0   True       strich.        VVFIN   \n",
            "68        konrad     8  PTKVZ          0   True       strich.        VVFIN   \n",
            "69        volkes     8  VVFIN          0   True       strich.        VVFIN   \n",
            "70        konrad     8  PTKVZ          0   True       strich.        VVFIN   \n",
            "71       Bündnis     8     NN          0   True       strich.        VVFIN   \n",
            "\n",
            "          PLL   PLL norm Number Evaluated Best N Ranking Rating  \\\n",
            "0  -32.353189  -3.235319               10      3       3      1   \n",
            "1  -33.020617  -2.751718               10      3       2      1   \n",
            "2  -34.925027  -2.910419               10      3       1      0   \n",
            "3  -33.020625  -2.751719               20      3       3      1   \n",
            "4  -39.554568  -3.296214               20      3       2      1   \n",
            "..        ...        ...              ...    ...     ...    ...   \n",
            "67 -64.709541 -10.784923               20      3       2      1   \n",
            "68 -65.365941 -10.894324               20      3       1      1   \n",
            "69 -64.709541 -10.784923               30      3       3      1   \n",
            "70 -65.365941 -10.894324               30      3       2      1   \n",
            "71 -65.570376  -9.367197               30      3       1      1   \n",
            "\n",
            "    Evaluation Time  \n",
            "0          0.663419  \n",
            "1          0.663419  \n",
            "2          0.663419  \n",
            "3          0.212757  \n",
            "4          0.212757  \n",
            "..              ...  \n",
            "67         0.317708  \n",
            "68         0.317708  \n",
            "69         0.556638  \n",
            "70         0.556638  \n",
            "71         0.556638  \n",
            "\n",
            "[72 rows x 14 columns]\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluonnlp/data/sampler.py:354: UserWarning: Some buckets are empty and will be removed. Unused bucket keys=[18]\n",
            "  str(unused_bucket_keys))\n"
          ]
        }
      ],
      "source": [
        "sent_ind = 0 #a nice and short sentence\n",
        "fill_sent = filler_sent_lists[sent_ind]\n",
        "fill_sent_copy = fill_sent[:]\n",
        "sent_len = len(fill_sent)\n",
        "print(sent_len)\n",
        "ind_list = [(-3,6),(3,sent_len+2), (2,5), (5,3)]\n",
        "batches = [10,20,30]\n",
        "#default start_ind and end_ind - just do the whole sentence\n",
        "print(test.compare_batches(batches,fill_sent,sent_ind,3,filler=True))\n",
        "print(fill_sent == fill_sent_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omJV4_mClIq7",
        "outputId": "02651b12-fca0-44df-d4ad-0d7e4587a181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following start_ind/end_ind pair raised a ValueError: (-3, 6)\n",
            "The following start_ind/end_ind pair raised a ValueError: (3, 11)\n",
            "Round 1/9: Find distractor for word at index 2 by comparing 10 potential distractors\n",
            "5.72\n",
            "Time to evaluate >10 distractors: 0.21388554573059082\n",
            "Final parameter settings: 5.819999999999999 0.2\n",
            "Thomas beobachtete Weiss [seinen]\n",
            "Unacceptable? 0\n",
            "Thomas beobachtete sollte [seinen]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete hast [seinen]\n",
            "Unacceptable? 1\n",
            "Round 2/9: Find distractor for word at index 2 by comparing 20 potential distractors\n",
            "5.72\n",
            "Time to evaluate >20 distractors: 0.2118053436279297\n",
            "Final parameter settings: 5.819999999999999 0.2\n",
            "Distractor hast already rated 1\n",
            "Thomas beobachtete warum [seinen]\n",
            "Unacceptable? 0\n",
            "Thomas beobachtete sowie [seinen]\n",
            "Unacceptable? 0\n",
            "Round 3/9: Find distractor for word at index 2 by comparing 30 potential distractors\n",
            "5.72\n",
            "Time to evaluate >30 distractors: 0.22357797622680664\n",
            "Final parameter settings: 5.819999999999999 0.2\n",
            "Thomas beobachtete andere [seinen]\n",
            "Unacceptable? 0\n",
            "Distractor warum already rated 0\n",
            "Distractor sowie already rated 0\n",
            "Round 4/9: Find distractor for word at index 3 by comparing 10 potential distractors\n",
            "4.61\n",
            "Time to evaluate >10 distractors: 0.20946574211120605\n",
            "Final parameter settings: 4.71 0.2\n",
            "Thomas beobachtete seinen getötet [Nachbarn]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Aufnahme [Nachbarn]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen aussagen [Nachbarn]\n",
            "Unacceptable? 1\n",
            "Round 5/9: Find distractor for word at index 3 by comparing 20 potential distractors\n",
            "4.61\n",
            "Time to evaluate >20 distractors: 0.31282711029052734\n",
            "Final parameter settings: 4.71 0.2\n",
            "Distractor aussagen already rated 1\n",
            "Thomas beobachtete seinen erfüllt [Nachbarn]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Weshalb [Nachbarn]\n",
            "Unacceptable? 1\n",
            "Round 6/9: Find distractor for word at index 3 by comparing 30 potential distractors\n",
            "4.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluonnlp/data/sampler.py:354: UserWarning: Some buckets are empty and will be removed. Unused bucket keys=[8, 9]\n",
            "  str(unused_bucket_keys))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to evaluate >30 distractors: 0.5278100967407227\n",
            "Final parameter settings: 4.71 0.2\n",
            "Distractor aussagen already rated 1\n",
            "Distractor erfüllt already rated 1\n",
            "Distractor Weshalb already rated 1\n",
            "Round 7/9: Find distractor for word at index 4 by comparing 10 potential distractors\n",
            "5.11\n",
            "Time to evaluate >10 distractors: 0.2130599021911621\n",
            "Final parameter settings: 5.21 0.2\n",
            "Thomas beobachtete seinen Nachbarn ihres, [Peter,]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn hält, [Peter,]\n",
            "Unacceptable? 1\n",
            "Thomas beobachtete seinen Nachbarn setzen, [Peter,]\n",
            "Unacceptable? 1\n",
            "Round 8/9: Find distractor for word at index 4 by comparing 20 potential distractors\n",
            "5.11\n",
            "Time to evaluate >20 distractors: 0.21320581436157227\n",
            "Final parameter settings: 5.21 0.2\n",
            "Distractor ihres already rated 1\n",
            "Distractor hält already rated 1\n",
            "Distractor setzen already rated 1\n",
            "Round 9/9: Find distractor for word at index 4 by comparing 30 potential distractors\n",
            "5.11\n",
            "Time to evaluate >30 distractors: 0.21512913703918457\n",
            "Final parameter settings: 5.21 0.2\n",
            "Distractor hält already rated 1\n",
            "Thomas beobachtete seinen Nachbarn sachen, [Peter,]\n",
            "Unacceptable? 0\n",
            "Distractor setzen already rated 1\n",
            "The following start_ind/end_ind pair raised a ValueError: (5, 3)\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "for inds in ind_list:\n",
        "  start_ind,end_ind=inds\n",
        "  try:\n",
        "   test.compare_batches(batches,fill_sent,sent_ind,3,start_ind,end_ind,filler=True)\n",
        "  except ValueError:\n",
        "    print(f\"The following start_ind/end_ind pair raised a ValueError: {inds}\")\n",
        "print(fill_sent == fill_sent_copy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}